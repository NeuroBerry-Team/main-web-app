[2025-08-04: 23:57:06] [inferences] > Error generating inference for 06793de5c0634036b22d5b243460f8c2/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99d76c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 00:07:18] [inferences] > Error generating inference for 2b6550666b0248fb87186a04c597154f/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99f4380>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 00:09:59] [inferences] > Error generating inference for 2b6550666b0248fb87186a04c597154f/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99f51c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 00:21:39] [inferences] > Error generating inference for 2b6550666b0248fb87186a04c597154f/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99f64c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 01:04:42] [inferences] > Error generating inference for 7e97d891273b4c50a5bae2cdb8b1c771/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a88015c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 01:06:18] [inferences] > Error generating inference for 9724eff2ab6e4c95b442c182dde77dfe/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99af700>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 01:07:31] [inferences] > Error generating inference for 9724eff2ab6e4c95b442c182dde77dfe/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69a99d8980>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia
[2025-08-05: 01:08:05] [inferences] > Error generating inference for 9724eff2ab6e4c95b442c182dde77dfe/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia'), <traceback object at 0x7f69ab56e0c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: UNAUTHORIZED for url: http://192.168.100.79:8080/inferencia
[2025-08-23: 00:01:54] [inferences] > Presigned S3 error >> (<class 'urllib3.exceptions.MaxRetryError'>, MaxRetryError("HTTPConnectionPool(host='192.168.100.79', port=9000): Max retries exceeded with url: /inferences?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e8b857150>: Failed to establish a new connection: [Errno 113] No route to host'))"), <traceback object at 0x7f9e8b8542c0>)
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/usr/local/lib/python3.11/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
OSError: [Errno 113] No route to host

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.11/http/client.py", line 1298, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.11/http/client.py", line 1058, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.11/http/client.py", line 996, in send
    self.connect()
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9e8b857150>: Failed to establish a new connection: [Errno 113] No route to host

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 47, in getBaseImgPresignedUrls
    imgUploadUrl = minioClient.presigned_put_object(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/minio/api.py", line 2444, in presigned_put_object
    return self.get_presigned_url(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/minio/api.py", line 2339, in get_presigned_url
    region = self._get_region(bucket_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/minio/api.py", line 495, in _get_region
    response = self._url_open(
               ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/minio/api.py", line 303, in _url_open
    response = self._http.urlopen(
               ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 873, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 873, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 873, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  [Previous line repeated 2 more times]
  File "/usr/local/lib/python3.11/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='192.168.100.79', port=9000): Max retries exceeded with url: /inferences?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e8b857150>: Failed to establish a new connection: [Errno 113] No route to host'))
[2025-08-23: 04:50:24] [inferences] > Error generating inference for e7e36ab0c62648978b61ca4346dae31d/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia'), <traceback object at 0x7fe448c81080>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia
[2025-08-23: 04:51:23] [inferences] > Error generating inference for e7e36ab0c62648978b61ca4346dae31d/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia'), <traceback object at 0x7fe4488d91c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia
[2025-08-23: 06:39:31] [inferences] > Error generating inference for bd816cda2b4743b79e09dbdac742807b/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: Internal Server Error for url: http://192.168.100.80:8080/inferencia'), <traceback object at 0x7f6a34435e00>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 85, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://192.168.100.80:8080/inferencia
[2025-08-26: 21:22:33] [error_handler] > Unexpected error occurred >> (<class 'TypeError'>, TypeError("rate_limit_login.<locals>.decorator() missing 1 required positional argument: 'f'"), <traceback object at 0x7f5c4d3f5cc0>)
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 867, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 852, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: rate_limit_login.<locals>.decorator() missing 1 required positional argument: 'f'
[2025-08-26: 21:22:33] [error_handler] > Server error occurred >> None
[2025-08-26: 21:37:31] [auth] > Error generating CSRF token >> (<class 'RuntimeError'>, RuntimeError('The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.'), <traceback object at 0x7fb8aa664100>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 255, in get_csrf_token_endpoint
    token = get_csrf_token()
            ^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 164, in get_csrf_token
    return csrf.generate_csrf_token()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 129, in generate_csrf_token
    session['_csrf_session_id'] = session_id
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/sessions.py", line 97, in _fail
    raise RuntimeError(
RuntimeError: The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.
[2025-08-26: 21:38:05] [auth] > Error generating CSRF token >> (<class 'RuntimeError'>, RuntimeError('The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.'), <traceback object at 0x7fb8a9337380>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 255, in get_csrf_token_endpoint
    token = get_csrf_token()
            ^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 164, in get_csrf_token
    return csrf.generate_csrf_token()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 129, in generate_csrf_token
    session['_csrf_session_id'] = session_id
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/sessions.py", line 97, in _fail
    raise RuntimeError(
RuntimeError: The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.
[2025-08-26: 21:40:11] [auth] > Error generating CSRF token >> (<class 'RuntimeError'>, RuntimeError('The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.'), <traceback object at 0x7fbba58719c0>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 255, in get_csrf_token_endpoint
    token = get_csrf_token()
            ^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 164, in get_csrf_token
    return csrf.generate_csrf_token()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 129, in generate_csrf_token
    session['_csrf_session_id'] = session_id
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/sessions.py", line 97, in _fail
    raise RuntimeError(
RuntimeError: The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.
[2025-08-26: 21:40:30] [auth] > Error generating CSRF token >> (<class 'RuntimeError'>, RuntimeError('The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.'), <traceback object at 0x7fbba45612c0>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 255, in get_csrf_token_endpoint
    token = get_csrf_token()
            ^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 164, in get_csrf_token
    return csrf.generate_csrf_token()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 129, in generate_csrf_token
    session['_csrf_session_id'] = session_id
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/sessions.py", line 97, in _fail
    raise RuntimeError(
RuntimeError: The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.
[2025-08-26: 21:46:30] [auth] > Error generating CSRF token >> (<class 'RuntimeError'>, RuntimeError('The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.'), <traceback object at 0x7fa33fd3eac0>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 255, in get_csrf_token_endpoint
    token = get_csrf_token()
            ^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 164, in get_csrf_token
    return csrf.generate_csrf_token()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/security/csrf_protection.py", line 129, in generate_csrf_token
    session['_csrf_session_id'] = session_id
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/sessions.py", line 97, in _fail
    raise RuntimeError(
RuntimeError: The session is unavailable because no secret key was set.  Set the secret_key on the application to something unique and secret.
[2025-08-26: 22:30:49] [auth] > Default role AI_USER not found >> None
[2025-08-26: 22:30:49] [auth] > Error finding default role during registration >> (<class 'werkzeug.exceptions.InternalServerError'>, <InternalServerError '500: Internal Server Error'>, <traceback object at 0x7f842d26f700>)
Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 119, in register
    abort(500, 'Registration failed - invalid role configuration')
  File "/usr/local/lib/python3.11/site-packages/flask/helpers.py", line 274, in abort
    current_app.aborter(code, *args, **kwargs)
  File "/usr/local/lib/python3.11/site-packages/werkzeug/exceptions.py", line 861, in __call__
    raise self.mapping[code](*args, **kwargs)
werkzeug.exceptions.InternalServerError: 500 Internal Server Error: Registration failed - invalid role configuration
[2025-08-29: 01:22:37] [inferences] > Error saving in DB inference of 1/e00b204e149f43509e4cb6634121e3b0/original_img.jpg >> (<class 'sqlalchemy.exc.NoReferencedTableError'>, NoReferencedTableError("Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'"), <traceback object at 0x7f33d256db40>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 155, in generateInference
    db.session.commit()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/scoping.py", line 597, in commit
    return self._proxied.commit()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2017, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1302, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1277, in _prepare_impl
    self.session.flush()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4341, in flush
    self._flush(objects)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4476, in _flush
    with util.safe_reraise():
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4437, in _flush
    flush_context.execute()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 76, in save_obj
    for table, mapper in base_mapper._sorted_tables.items():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1253, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4050, in _sorted_tables
    sorted_ = sql_util.sort_tables(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1252, in sort_tables
    for (t, fkcs) in sort_tables_and_constraints(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1322, in sort_tables_and_constraints
    filtered = filter_fn(fkc)
               ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1242, in _skip_fn
    if fixed_skip_fn(fk):
       ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4033, in skip
    dep = table_to_mapper.get(fk.column.table)
                              ^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1141, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3159, in column
    return self._resolve_column()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3182, in _resolve_column
    raise exc.NoReferencedTableError(
sqlalchemy.exc.NoReferencedTableError: Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'
[2025-08-29: 01:29:28] [inferences] > Error saving in DB inference of 1/ba945f0e69564b4a917b6ebe26c68999/original_img.jpg >> (<class 'sqlalchemy.exc.NoReferencedTableError'>, NoReferencedTableError("Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'"), <traceback object at 0x7f2f377034c0>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 155, in generateInference
    db.session.commit()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/scoping.py", line 597, in commit
    return self._proxied.commit()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2017, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1302, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1277, in _prepare_impl
    self.session.flush()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4341, in flush
    self._flush(objects)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4476, in _flush
    with util.safe_reraise():
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4437, in _flush
    flush_context.execute()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 76, in save_obj
    for table, mapper in base_mapper._sorted_tables.items():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1253, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4050, in _sorted_tables
    sorted_ = sql_util.sort_tables(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1252, in sort_tables
    for (t, fkcs) in sort_tables_and_constraints(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1322, in sort_tables_and_constraints
    filtered = filter_fn(fkc)
               ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1242, in _skip_fn
    if fixed_skip_fn(fk):
       ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4033, in skip
    dep = table_to_mapper.get(fk.column.table)
                              ^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1141, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3159, in column
    return self._resolve_column()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3182, in _resolve_column
    raise exc.NoReferencedTableError(
sqlalchemy.exc.NoReferencedTableError: Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'
[2025-08-29: 01:30:09] [inferences] > Error saving in DB inference of 1/d704d53ae9904f25a5906644cc8897d0/original_img.jpg >> (<class 'sqlalchemy.exc.NoReferencedTableError'>, NoReferencedTableError("Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'"), <traceback object at 0x7f01fea2a000>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 155, in generateInference
    db.session.commit()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/scoping.py", line 597, in commit
    return self._proxied.commit()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2017, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1302, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1277, in _prepare_impl
    self.session.flush()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4341, in flush
    self._flush(objects)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4476, in _flush
    with util.safe_reraise():
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4437, in _flush
    flush_context.execute()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 76, in save_obj
    for table, mapper in base_mapper._sorted_tables.items():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1253, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4050, in _sorted_tables
    sorted_ = sql_util.sort_tables(
              ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1252, in sort_tables
    for (t, fkcs) in sort_tables_and_constraints(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1322, in sort_tables_and_constraints
    filtered = filter_fn(fkc)
               ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py", line 1242, in _skip_fn
    if fixed_skip_fn(fk):
       ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/mapper.py", line 4033, in skip
    dep = table_to_mapper.get(fk.column.table)
                              ^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 1141, in __get__
    obj.__dict__[self.__name__] = result = self.fget(obj)
                                           ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3159, in column
    return self._resolve_column()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py", line 3182, in _resolve_column
    raise exc.NoReferencedTableError(
sqlalchemy.exc.NoReferencedTableError: Foreign key associated with column 'inferences.modelId' could not find table 'models' with which to generate a foreign key to target column 'id'
[2025-08-29: 05:22:47] [models] > Error starting model training: 'InputValidator' object has no attribute 'validate_string' >> None
[2025-08-29: 05:22:47] [audit] > Error logging audit action: 'InputValidator' object has no attribute 'validate_string' >> None
[2025-08-29: 05:26:21] [models] > Error starting model training: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "models_pkey"
DETAIL:  Key (id)=(1) already exists.

[SQL: INSERT INTO models (name, version, description, "modelType", "createdOn", "updatedOn") VALUES (%(name)s, %(version)s, %(description)s, %(modelType)s, %(createdOn)s, %(updatedOn)s) RETURNING models.id]
[parameters: {'name': 'xdxd', 'version': '1.0', 'description': 'xdxd', 'modelType': 'YOLOv8_m', 'createdOn': datetime.datetime(2025, 8, 29, 5, 26, 21, 944139), 'updatedOn': datetime.datetime(2025, 8, 29, 5, 26, 21, 944142)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 00:33:45] [inferences] > Error generating inference for 1/7ce2561c984643e4b46289810f798275/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia/inferencia'), <traceback object at 0x7ff9ccfebc00>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 134, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://192.168.100.80:8080/inferencia/inferencia
[2025-08-30: 22:38:00] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "datasets_pkey"
DETAIL:  Key (id)=(1) already exists.

[SQL: INSERT INTO datasets (name, description, "datasetType", "s3Path", "createdBy", "createdOn") VALUES (%(name)s, %(description)s, %(datasetType)s, %(s3Path)s, %(createdBy)s, %(createdOn)s) RETURNING datasets.id]
[parameters: {'name': 'datasetv2', 'description': 'Auto-synced dataset from MinIO: datasetv2.zip', 'datasetType': 'YOLO', 's3Path': 's3://dataset/datasetv2.zip', 'createdBy': 1, 'createdOn': datetime.datetime(2025, 8, 30, 22, 38, 0, 366818)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 22:38:19] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "datasets_pkey"
DETAIL:  Key (id)=(2) already exists.

[SQL: INSERT INTO datasets (name, description, "datasetType", "s3Path", "createdBy", "createdOn") VALUES (%(name)s, %(description)s, %(datasetType)s, %(s3Path)s, %(createdBy)s, %(createdOn)s) RETURNING datasets.id]
[parameters: {'name': 'datasetv2', 'description': 'Auto-synced dataset from MinIO: datasetv2.zip', 'datasetType': 'YOLO', 's3Path': 's3://dataset/datasetv2.zip', 'createdBy': 1, 'createdOn': datetime.datetime(2025, 8, 30, 22, 38, 19, 424304)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 22:38:26] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "datasets_pkey"
DETAIL:  Key (id)=(3) already exists.

[SQL: INSERT INTO datasets (name, description, "datasetType", "s3Path", "createdBy", "createdOn") VALUES (%(name)s, %(description)s, %(datasetType)s, %(s3Path)s, %(createdBy)s, %(createdOn)s) RETURNING datasets.id]
[parameters: {'name': 'datasetv2', 'description': 'Auto-synced dataset from MinIO: datasetv2.zip', 'datasetType': 'YOLO', 's3Path': 's3://dataset/datasetv2.zip', 'createdBy': 1, 'createdOn': datetime.datetime(2025, 8, 30, 22, 38, 26, 438698)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 22:44:04] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:12] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:19] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:25] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:46] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:53] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:44:59] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:45:16] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:56:31] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:56:33] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:57:44] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedColumn) column datasets.active does not exist
LINE 1: ...y", datasets."createdOn" AS "datasets_createdOn", datasets.a...
                                                             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-08-30: 22:58:27] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AD945A4908B1, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 22:58:29] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AD94CAF580F0, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 22:58:30] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AD9501B518C2, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 22:58:30] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AD952C28FA6E, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:27:32] [models] > Error starting model training: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "models_pkey"
DETAIL:  Key (id)=(1) already exists.

[SQL: INSERT INTO models (name, version, description, "modelType", "createdOn", "updatedOn") VALUES (%(name)s, %(version)s, %(description)s, %(modelType)s, %(createdOn)s, %(updatedOn)s) RETURNING models.id]
[parameters: {'name': 'xdxdxd', 'version': '1.0', 'description': 'xdxdxd', 'modelType': 'YOLOv8_m', 'createdOn': datetime.datetime(2025, 8, 30, 23, 27, 32, 816298), 'updatedOn': datetime.datetime(2025, 8, 30, 23, 27, 32, 816300)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 23:29:31] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AF4651F3ED54, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:29:32] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AF46AC322D20, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:29:34] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AF4703876BC8, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:29:35] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AF473EB1BADC, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:30:33] [models] > Error starting model training: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "models_pkey"
DETAIL:  Key (id)=(1) already exists.

[SQL: INSERT INTO models (name, version, description, "modelType", "createdOn", "updatedOn") VALUES (%(name)s, %(version)s, %(description)s, %(modelType)s, %(createdOn)s, %(updatedOn)s) RETURNING models.id]
[parameters: {'name': 'xdxdxdx', 'version': '1.0', 'description': 'xdxdxd', 'modelType': 'YOLOv8_m', 'createdOn': datetime.datetime(2025, 8, 30, 23, 30, 33, 357280), 'updatedOn': datetime.datetime(2025, 8, 30, 23, 30, 33, 357282)}]
(Background on this error at: https://sqlalche.me/e/20/gkpj) >> None
[2025-08-30: 23:33:27] [models] > NN API error: 400 Client Error: Bad Request for url: http://192.168.100.80:8080//training >> None
[2025-08-30: 23:38:33] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AFC48C20DA16, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:38:34] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AFC4E5D2E24D, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:38:36] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AFC53B226960, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:38:37] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1860AFC574711E6E, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:38:38] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: AccessDenied, message: Access Denied., resource: /dataset, request_id: 1860AFC5A141C431, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-08-30: 23:40:09] [models] > NN API error: 400 Client Error: Bad Request for url: http://192.168.100.80:8080//training >> None
[2025-08-30: 23:46:19] [models] > NN API error: 500 Server Error: Internal Server Error for url: http://192.168.100.80:8080//training >> None
[2025-08-31: 00:24:01] [models] > NN API error getting training jobs: HTTPConnectionPool(host='192.168.100.80', port=8080): Max retries exceeded with url: /training (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9c2ffa5fd0>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-08-31: 02:05:20] [models] > NN API error getting training jobs: 401 Client Error: Unauthorized for url: http://192.168.100.80:8080//training >> None
[2025-08-31: 02:05:20] [models] > NN API error cancelling job 6e82dba9-86d9-42f0-a403-1b439c8e5b17: 500 Server Error: Internal Server Error for url: http://192.168.100.80:8080//training/6e82dba9-86d9-42f0-a403-1b439c8e5b17 >> None
[2025-08-31: 23:56:31] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-01: 00:10:59] [auth] > Error creating user session >> (<class 'sqlalchemy.exc.ProgrammingError'>, ProgrammingError('(psycopg2.errors.UndefinedTable) relation "user_sessions" does not exist\nLINE 1: INSERT INTO user_sessions ("userId", "loginAt", "logoutAt", ...\n                    ^\n'), <traceback object at 0x7fa6a9de2740>)
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "user_sessions" does not exist
LINE 1: INSERT INTO user_sessions ("userId", "loginAt", "logoutAt", ...
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/src/routes/auth.py", line 239, in login
    db.session.commit()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/scoping.py", line 597, in commit
    return self._proxied.commit()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2017, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1302, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1277, in _prepare_impl
    self.session.flush()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4341, in flush
    self._flush(objects)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4476, in _flush
    with util.safe_reraise():
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 4437, in _flush
    flush_context.execute()
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1233, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
           ^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2353, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "user_sessions" does not exist
LINE 1: INSERT INTO user_sessions ("userId", "loginAt", "logoutAt", ...
                    ^

[SQL: INSERT INTO user_sessions ("userId", "loginAt", "logoutAt", "ipAddress", "userAgent") VALUES (%(userId)s, %(loginAt)s, %(logoutAt)s, %(ipAddress)s, %(userAgent)s) RETURNING user_sessions.id]
[parameters: {'userId': 1, 'loginAt': datetime.datetime(2025, 9, 1, 0, 10, 59, 187449), 'logoutAt': None, 'ipAddress': '172.19.0.1', 'userAgent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
[2025-09-01: 00:12:23] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 18610031BD945BCE, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:12:24] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186100321AF08CAB, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:12:25] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 18610032544295C6, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:12:26] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186100327DF517F9, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:15:04] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186100573506C416, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:15:05] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186100579EE3BC62, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:15:06] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 18610057DB7E1E2A, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-01: 00:15:07] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 1861005807A18046, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:41:17] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153A0304C6735, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:41:18] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153A09A51C707, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:41:20] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153A100109CB1, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:41:22] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:41:26] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:41:30] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:41:36] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:41:44] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:41:58] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:42:25] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:43:18] [dataset_sync] > Error during dataset synchronization: (psycopg2.errors.UndefinedTable) relation "datasets" does not exist
LINE 2: FROM datasets
             ^

[SQL: SELECT datasets.id AS datasets_id, datasets.name AS datasets_name, datasets.description AS datasets_description, datasets."datasetType" AS "datasets_datasetType", datasets."s3Path" AS "datasets_s3Path", datasets."createdBy" AS "datasets_createdBy", datasets."createdOn" AS "datasets_createdOn", datasets.active AS datasets_active 
FROM datasets]
(Background on this error at: https://sqlalche.me/e/20/f405) >> None
[2025-09-02: 01:44:01] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153C675E8C796, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:44:03] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153C6DBC9A95D, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:44:04] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153C71E0152B9, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:44:05] [dataset_sync] > Error accessing MinIO bucket 'dataset': S3 operation failed; code: InvalidAccessKeyId, message: The Access Key Id you provided does not exist in our records., resource: /dataset, request_id: 186153C749ADC483, host_id: 411bc421bd2f80bc9878e776fea40bf4f4a112865b490a39fb326fa1e5ad1a8e, bucket_name: dataset >> None
[2025-09-02: 01:57:47] [inferences] > Error fetching metadata for inference 1 >> (<class 'werkzeug.exceptions.NotFound'>, <NotFound '404: Not Found'>, <traceback object at 0x7f6c17e3e940>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 231, in getInferenceMetadata
    abort(404, 'Metadata not found')
  File "/usr/local/lib/python3.11/site-packages/flask/helpers.py", line 274, in abort
    current_app.aborter(code, *args, **kwargs)
  File "/usr/local/lib/python3.11/site-packages/werkzeug/exceptions.py", line 861, in __call__
    raise self.mapping[code](*args, **kwargs)
werkzeug.exceptions.NotFound: 404 Not Found: Metadata not found
[2025-09-02: 02:08:21] [inferences] > Error fetching metadata for inference 1 >> (<class 'werkzeug.exceptions.NotFound'>, <NotFound '404: Not Found'>, <traceback object at 0x7f7f33ebe540>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 206, in getInferenceMetadata
    abort(404, 'Metadata not found')
  File "/usr/local/lib/python3.11/site-packages/flask/helpers.py", line 274, in abort
    current_app.aborter(code, *args, **kwargs)
  File "/usr/local/lib/python3.11/site-packages/werkzeug/exceptions.py", line 861, in __call__
    raise self.mapping[code](*args, **kwargs)
werkzeug.exceptions.NotFound: 404 Not Found: Metadata not found
[2025-09-08: 00:07:37] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efcba38ba10>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:07:51] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f063fa3fa90>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:07:58] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba30356650>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:08:05] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f083f1fec50>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:13:12] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fce74d37490>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:13:20] [dataset_sync] > Error accessing MinIO bucket 'dataset': HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /dataset?location= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0b9a012550>: Failed to establish a new connection: [Errno 111] Connection refused')) >> None
[2025-09-08: 00:40:26] [inferences] > Error generating inference for 1/288cdb4e4b78455890156c3031bee097/original_img.jpg >> (<class 'requests.exceptions.HTTPError'>, HTTPError('500 Server Error: Internal Server Error for url: http://192.168.100.85:8080//inferencia'), <traceback object at 0x7f54b2e03a80>)
Traceback (most recent call last):
  File "/app/src/routes/inferences.py", line 134, in generateInference
    json_response = nnClient.generateInference(payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/cloudServices/nnApiConnections.py", line 44, in generateInference
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://192.168.100.85:8080//inferencia
